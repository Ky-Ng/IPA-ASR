{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "- Splits the TIMIT dataset into a `TRAIN`, `VALIDATION`, `TEST` dataset\n",
    "- Note: the TIMIT dataset already comes with a `TEST` folder so we will simply take a % of the `TEST` dataset for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Import Audio\n",
    "- Create Training Dataset\n",
    "- Create Test Dataset\n",
    "- Since TIMIT does not differentiate between Test and Validation, we will manually split the Test into Test and Validation as a downstream task to respect the original naming conventions of the TIMIT dataset\n",
    "\n",
    "### Motivation\n",
    "The motivation for creating this dataset is because the existing `timit_asr` Hugging Face datasets do not use the complete TIMIT `TEST` and `TRAIN` data available. \n",
    "\n",
    "In addition, we also add  speaker gender and duration of speech.\n",
    "\n",
    "### Linguistic Distinction in categories\n",
    "`SA` = \"Speaker Accent\"/Dialect or Shibboleth sentences designed to highlight dialect region differences\n",
    "`SX` = Phonetically Compact sentences designed to highlight pairs of phones of interest (i.e. voiced vs unvoiced velar stops) in specific phonetic contexts (i.e. coda position = at the end of a word)\n",
    "`SI` = Phonetically Diverse sentences designed to highlight many different phonemes and sentence types per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleng/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio, DatasetDict, load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timit_metadata_extractors import get_transcription_detail, get_speech_duration, get_replace_ending, get_timit_path, get_speaker_info, get_sentence_info, get_text, get_ipa_transcription\n",
    "from timit_dataset_splitter import stratify_timt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TIMIT = \"../data/input_data/TIMIT-Database/TIMIT\"\n",
    "UPLOAD_TIMIT_BASE_NAME = \"kylelovesllms/timit_asr\"\n",
    "UPLOAD_TIMIT_IPA_NAME = \"kylelovesllms/timit_asr_ipa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(dir: str, file_type: str = \"wav\") -> dict[tuple[str, list[str]], tuple[str, list[str]]]:\n",
    "    \"\"\"\n",
    "    Walks through every directory in `dir` and returns all files which end in `file_type`\n",
    "    \"\"\"\n",
    "\n",
    "    audio_paths = []\n",
    "\n",
    "    # Walk through each directory\n",
    "    for dirpath, _dirnames, filenames in os.walk(dir):\n",
    "        # Check each file in the directory\n",
    "        for file_name in filenames:\n",
    "            # If the `file_type` matches\n",
    "            if file_name.endswith(file_type):\n",
    "                # Add that file\n",
    "                full_local_path = os.path.join(dirpath, file_name)\n",
    "                audio_paths.append(full_local_path)\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local paths ['../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX139.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SA2.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX229.wav']\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check that we get the appropriate local paths and task names\n",
    "paths = get_audio_files(\"../data/input_data/TIMIT-Database/TIMIT/TEST\")\n",
    "print(\"local paths\", paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(PATH_TO_TIMIT, \"TRAIN\")\n",
    "testvalidation_path = os.path.join(PATH_TO_TIMIT, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(train_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())\n",
    "\n",
    "testvalidation_dataset = Dataset.from_dict(\n",
    "     {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())\n",
    "\n",
    "# TODO REMOVE AFTER DEBUGGING\n",
    "# train_dataset = Dataset.from_dict(\n",
    "#     {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(train_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())\n",
    "\n",
    "# testvalidation_dataset = Dataset.from_dict(\n",
    "#      {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 3629\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../data/input_data/TIMIT-Database/TIMIT/TRAIN/DR4/MMDM0/SI681.wav',\n",
       " 'array': array([-2.13623047e-04,  6.10351562e-05,  3.05175781e-05, ...,\n",
       "        -3.05175781e-05, -9.15527344e-05, -6.10351562e-05]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity check to make sure we have valid audio files\n",
    "train_dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Add Metadata\n",
    "Although not all of the metadata is needed for this specific project, perhaps others in the open-source community will find this metadata helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata(example):\n",
    "    \"\"\"\n",
    "    Adds transcriptions and metadata to the TIMIT dataset\n",
    "\n",
    "    Note: after using `example[\"audio\"]`, the `example[\"audio\"][\"path\"]` is \n",
    "    automatically set to None for security reasons\n",
    "    (see Github Issue: https://github.com/huggingface/datasets/issues/5190)\n",
    "    \"\"\"\n",
    "    wav_path = example[\"audio\"][\"path\"]\n",
    "\n",
    "    # Add Transcriptions\n",
    "    phn_file = get_replace_ending(wav_path, new_extension=\".phn\")\n",
    "    wrd_file = get_replace_ending(wav_path, new_extension=\".wrd\")\n",
    "    text_file = get_replace_ending(wav_path, new_extension=\".txt\")\n",
    "\n",
    "    example[\"phonetic_detail\"] = get_transcription_detail(phn_file)\n",
    "    example[\"word_detail\"] = get_transcription_detail(wrd_file)\n",
    "    example[\"text\"] = get_text(text_file)\n",
    "\n",
    "    # Speech Duration\n",
    "    example[\"duration\"] = get_speech_duration(\n",
    "        example[\"audio\"][\"array\"], sr=example[\"audio\"][\"sampling_rate\"])\n",
    "\n",
    "    # TIMIT Path\n",
    "    example[\"timit_path\"] = get_timit_path(\n",
    "        abs_path=wav_path, base_path=PATH_TO_TIMIT)\n",
    "\n",
    "    # Speaker Metadata\n",
    "    (dialect_region, dialect_region_name), (speaker_id, sex) = get_speaker_info(\n",
    "        example[\"timit_path\"])\n",
    "    example[\"dialect_region\"] = dialect_region\n",
    "    example[\"dialect_region_name\"] = dialect_region_name\n",
    "    example[\"speaker_id\"] = speaker_id\n",
    "    example[\"speaker_sex\"] = sex\n",
    "\n",
    "    # Sentence Metadata\n",
    "    sentence_id, sentence_type = get_sentence_info(wav_path)\n",
    "    example[\"id\"] = sentence_id\n",
    "    example[\"sentence_type\"] = sentence_type\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [01:28<00:00, 41.15 examples/s] \n",
      "Map:  74%|███████▍  | 989/1340 [00:12<00:00, 510.87 examples/s]"
     ]
    }
   ],
   "source": [
    "train_dataset_with_metadata = train_dataset.map(add_metadata)\n",
    "testvalidation_dataset_with_metadata = testvalidation_dataset.map(add_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3) Upload Dataset to HuggingFace Hub\n",
    "- Note: we will upload the `testvalidation_dataset_with_metadata` as `test` in the TIMIT tradition\n",
    "- We will also create a train/validation/test split and have more features extracted from the data but do so in a different repository to remain consistent with the original TIMIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_asr_dataset_base = DatasetDict({\n",
    "    \"train\": train_dataset_with_metadata,\n",
    "    \"test\": testvalidation_dataset_with_metadata\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 3629\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 1340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Upload and Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [00:00<00:00, 11695.28 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 37/37 [00:00<00:00, 106.20ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Map: 100%|██████████| 1340/1340 [00:00<00:00, 12452.84 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:00<00:00, 122.33ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kylelovesllms/timit_asr/commit/29c837c76686cb61f3efe199b0ea7d959b12f343', commit_message='Upload dataset', commit_description='', oid='29c837c76686cb61f3efe199b0ea7d959b12f343', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kylelovesllms/timit_asr', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kylelovesllms/timit_asr'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base.push_to_hub(UPLOAD_TIMIT_BASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_asr_dataset_base_from_hub = load_dataset(UPLOAD_TIMIT_BASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
      "        num_rows: 3629\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
      "        num_rows: 1340\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Verify that the repository is pulled down correctly\n",
    "print(timit_asr_dataset_base_from_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4) Adding Phonetic Transcriptions\n",
    "- Although the TIMIT IPA has a `phonetic_detail` which is documented in `TIMIT/DOC/PHONCODE.DOC`, some downstream use cases may require the use of transcription records in the International Phonetic Alphabet (IPA) format\n",
    "- This format is universal accross almost every tradition in phonetics \n",
    "- Note: the transcription scheme used in the repository below is not peer reviewed and is specific to a broad transcription for evaluating a fine tuned Wav2Vec2 model against Wav2Vec2-XLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ipa_transcription(example):\n",
    "    \"\"\"\n",
    "    Returns an interpretation of the IPA transcription in the `ipa_transcription` property\n",
    "    \"\"\"\n",
    "    example_with_metadata = add_metadata(example)\n",
    "    example_with_metadata[\"ipa_transcription\"] = get_ipa_transcription(example_with_metadata[\"phonetic_detail\"])\n",
    "    return example_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [01:28<00:00, 41.16 examples/s] \n",
      "Map: 100%|██████████| 1340/1340 [00:32<00:00, 40.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_with_ipa = train_dataset.map(add_ipa_transcription)\n",
    "testvalidation_dataset_with_ipa = testvalidation_dataset.map(add_ipa_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would such an act of refusal be useful?\n",
      "['h#', 'w', 'ix', 'dcl', 's', 'ah', 'tcl', 'ch', 'ix', 'n', 'ae', 'kcl', 't', 'ix', 'v', 'r', 'ix', 'f', 'y', 'ux', 'zh', 'el', 'bcl', 'b', 'iy', 'y', 'ux', 's', 'f', 'el', 'h#']\n",
      "['w', 'ɪ', 'd', 's', 'ʌ', 't', 'tʃ', 'ɪ', 'n', 'æ', 'k', 't', 'ɪ', 'v', 'r', 'ɪ', 'f', 'j', 'u', 'ʒ', 'l', 'b', 'i', 'j', 'u', 's', 'f', 'l']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the transcriptions\n",
    "print(train_dataset_with_ipa[0][\"text\"])\n",
    "print([seg[\"utterance\"] for seg in train_dataset_with_ipa[0][\"phonetic_detail\"]])\n",
    "print(train_dataset_with_ipa[0][\"ipa_transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bungalow was pleasantly situated near the shore.\n",
      "['h#', 'dh', 'ax', 'bcl', 'b', 'ah', 'ng', 'g', 'ax', 'l', 'ow', 'w', 'ax', 'z', 'pcl', 'p', 'l', 'eh', 'z', 'ax', 'n', 'q', 'l', 'iy', 's', 'ih', 'tcl', 'ch', 'uw', 'w', 'ey', 'dx', 'ix', 'dcl', 'n', 'ih', 'axr', 'dh', 'ix', 'sh', 'ao', 'r', 'h#']\n",
      "['ð', 'ə', 'b', 'ʌ', 'ŋ', 'g', 'ə', 'l', 'oʊ', 'w', 'ə', 'z', 'p', 'l', 'ɛ', 'z', 'ə', 'n', 'ʔ', 'l', 'i', 's', 'ɪ', 't', 'tʃ', 'u', 'w', 'eɪ', 'ɾ', 'ɪ', 'd', 'n', 'ɪ', 'ɚ', 'ð', 'ɪ', 'ʃ', 'ɔ', 'r']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the transcriptions\n",
    "print(testvalidation_dataset_with_ipa[0][\"text\"])\n",
    "print([seg[\"utterance\"] for seg in testvalidation_dataset_with_ipa[0][\"phonetic_detail\"]])\n",
    "print(testvalidation_dataset_with_ipa[0][\"ipa_transcription\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5) Add Validation Split\n",
    "- The original TIMIT dataset has only `TRAIN` and `TEST`\n",
    "- Thus, we will create an 80-10-10 `TRAIN`/ `VALIDATION` / `TEST`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification\n",
    "- The TIMIT dataset is carefully split into a `TRAIN` and `TEST` dataset.\n",
    "- When making the Validation dataset from splitting the `TEST` dataset in half, we want to `stratify` or keep the proportion of speakers the same to ensure accurate hyperparameter tuning and final test evaluation\n",
    "- The parameters that the TIMIT dataset stratifies on for `TRAIN` and `TEST` is `sex` and `dialect_region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset, test_dataset = stratify_timt_dataset(\n",
    "    testvalidation_dataset_with_ipa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect_region_name\n",
       "South Midland    160\n",
       "Southern         150\n",
       "North Midland    130\n",
       "Northern         130\n",
       "New York City     50\n",
       "New England       50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check that the dialect regions are balanced in validation set\n",
    "validation_dataset.to_pandas()[\"dialect_region_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect_region_name\n",
       "South Midland    160\n",
       "North Midland    130\n",
       "Northern         130\n",
       "Southern         130\n",
       "New York City     60\n",
       "New England       60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check that the dialect regions are balanced in test set\n",
    "test_dataset.to_pandas()[\"dialect_region_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6) Upload IPA and Validation Test split to HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_ipa_dataset = DatasetDict({\n",
    "    \"train\": train_dataset_with_ipa,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type', 'ipa_transcription'],\n",
       "        num_rows: 3629\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type', 'ipa_transcription'],\n",
       "        num_rows: 670\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type', 'ipa_transcription'],\n",
       "        num_rows: 670\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_ipa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None),\n",
       " 'phonetic_detail': [{'start': Value(dtype='int64', id=None),\n",
       "   'stop': Value(dtype='int64', id=None),\n",
       "   'utterance': Value(dtype='string', id=None)}],\n",
       " 'word_detail': [{'start': Value(dtype='int64', id=None),\n",
       "   'stop': Value(dtype='int64', id=None),\n",
       "   'utterance': Value(dtype='string', id=None)}],\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'duration': Value(dtype='float64', id=None),\n",
       " 'timit_path': Value(dtype='string', id=None),\n",
       " 'dialect_region': Value(dtype='string', id=None),\n",
       " 'dialect_region_name': Value(dtype='string', id=None),\n",
       " 'speaker_id': Value(dtype='string', id=None),\n",
       " 'speaker_sex': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'sentence_type': Value(dtype='string', id=None),\n",
       " 'ipa_transcription': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_ipa_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': Audio(sampling_rate=None, mono=True, decode=True, id=None),\n",
       " 'phonetic_detail': [{'start': Value(dtype='int64', id=None),\n",
       "   'stop': Value(dtype='int64', id=None),\n",
       "   'utterance': Value(dtype='string', id=None)}],\n",
       " 'word_detail': [{'start': Value(dtype='int64', id=None),\n",
       "   'stop': Value(dtype='int64', id=None),\n",
       "   'utterance': Value(dtype='string', id=None)}],\n",
       " 'text': Value(dtype='string', id=None),\n",
       " 'duration': Value(dtype='float64', id=None),\n",
       " 'timit_path': Value(dtype='string', id=None),\n",
       " 'dialect_region': Value(dtype='string', id=None),\n",
       " 'dialect_region_name': Value(dtype='string', id=None),\n",
       " 'speaker_id': Value(dtype='string', id=None),\n",
       " 'speaker_sex': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'sentence_type': Value(dtype='string', id=None),\n",
       " 'ipa_transcription': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_ipa_dataset[\"test\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [00:00<00:00, 11171.62 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 37/37 [00:00<00:00, 107.29ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:15<00:00, 15.75s/it]\n",
      "Map: 100%|██████████| 670/670 [00:00<00:00, 17092.33 examples/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 134.26ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n",
      "Map: 100%|██████████| 670/670 [00:00<00:00, 14541.17 examples/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 133.32ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kylelovesllms/timit_asr_ipa/commit/d696c0d9c28ab0ff17f3d1ce817688ffe95464a1', commit_message='Upload dataset', commit_description='', oid='d696c0d9c28ab0ff17f3d1ce817688ffe95464a1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kylelovesllms/timit_asr_ipa', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kylelovesllms/timit_asr_ipa'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_ipa_dataset.push_to_hub(UPLOAD_TIMIT_IPA_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
