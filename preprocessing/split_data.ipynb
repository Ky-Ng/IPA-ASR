{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "- Splits the TIMIT dataset into a `TRAIN`, `VALIDATION`, `TEST` dataset\n",
    "- Note: the TIMIT dataset already comes with a `TEST` folder so we will simply take a % of the `TEST` dataset for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Import Audio\n",
    "- Create Training Dataset\n",
    "- Create Test Dataset\n",
    "- Since TIMIT does not differentiate between Test and Validation, we will manually split the Test into Test and Validation as a downstream task to respect the original naming conventions of the TIMIT dataset\n",
    "\n",
    "### Motivation\n",
    "The motivation for creating this dataset is because the existing `timit_asr` Hugging Face datasets do not use the complete TIMIT `TEST` and `TRAIN` data available. \n",
    "\n",
    "In addition, we also add  speaker gender and duration of speech.\n",
    "\n",
    "### Linguistic Distinction in categories\n",
    "`SA` = \"Speaker Accent\"/Dialect or Shibboleth sentences designed to highlight dialect region differences\n",
    "`SX` = Phonetically Compact sentences designed to highlight pairs of phones of interest (i.e. voiced vs unvoiced velar stops) in specific phonetic contexts (i.e. coda position = at the end of a word)\n",
    "`SI` = Phonetically Diverse sentences designed to highlight many different phonemes and sentence types per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio, DatasetDict, load\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timit_metadata_extractors import get_transcription_detail, get_speech_duration, get_replace_ending, get_timit_path, get_speaker_info, get_sentence_info, get_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TIMIT = \"../data/input_data/TIMIT-Database/TIMIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(dir: str, file_type: str = \"wav\") -> dict[tuple[str, list[str]], tuple[str, list[str]]]:\n",
    "    \"\"\"\n",
    "    Walks through every directory in `dir` and returns all files which end in `file_type`\n",
    "    \"\"\"\n",
    "\n",
    "    audio_paths = []\n",
    "\n",
    "    # Walk through each directory\n",
    "    for dirpath, _dirnames, filenames in os.walk(dir):\n",
    "        # Check each file in the directory\n",
    "        for file_name in filenames:\n",
    "            # If the `file_type` matches\n",
    "            if file_name.endswith(file_type):\n",
    "                # Add that file\n",
    "                full_local_path = os.path.join(dirpath, file_name)\n",
    "                audio_paths.append(full_local_path)\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local paths ['../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX139.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SA2.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX229.wav']\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check that we get the appropriate local paths and task names\n",
    "paths = get_audio_files(\"../data/input_data/TIMIT-Database/TIMIT/TEST\")\n",
    "print(\"local paths\", paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(PATH_TO_TIMIT, \"TRAIN\")\n",
    "testvalidation_path = os.path.join(PATH_TO_TIMIT, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO REMOVE AFTER DEBUGGING\n",
    "# train_dataset = Dataset.from_dict(\n",
    "#     {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(train_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())\n",
    "\n",
    "# testvalidation_dataset = Dataset.from_dict(\n",
    "#      {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())\n",
    "\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(train_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())\n",
    "\n",
    "testvalidation_dataset = Dataset.from_dict(\n",
    "     {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 3629\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../data/input_data/TIMIT-Database/TIMIT/TRAIN/DR4/MMDM0/SI681.wav',\n",
       " 'array': array([-2.13623047e-04,  6.10351562e-05,  3.05175781e-05, ...,\n",
       "        -3.05175781e-05, -9.15527344e-05, -6.10351562e-05]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity check to make sure we have valid audio files\n",
    "train_dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Add Metadata\n",
    "Although not all of the metadata is needed for this specific project, perhaps others in the open-source community will find this metadata helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata(example):\n",
    "    \"\"\"\n",
    "    Adds transcriptions and metadata to the TIMIT dataset\n",
    "\n",
    "    Note: after using `example[\"audio\"]`, the `example[\"audio\"][\"path\"]` is \n",
    "    automatically set to None for security reasons\n",
    "    (see Github Issue: https://github.com/huggingface/datasets/issues/5190)\n",
    "    \"\"\"\n",
    "    wav_path = example[\"audio\"][\"path\"]\n",
    "\n",
    "    # Add Transcriptions\n",
    "    phn_file = get_replace_ending(wav_path, new_extension=\".phn\")\n",
    "    wrd_file = get_replace_ending(wav_path, new_extension=\".wrd\")\n",
    "    text_file = get_replace_ending(wav_path, new_extension=\".txt\")\n",
    "\n",
    "    example[\"phonetic_detail\"] = get_transcription_detail(phn_file)\n",
    "    example[\"word_detail\"] = get_transcription_detail(wrd_file)\n",
    "    example[\"text\"] = get_text(text_file)\n",
    "\n",
    "    # Speech Duration\n",
    "    example[\"duration\"] = get_speech_duration(\n",
    "        example[\"audio\"][\"array\"], sr=example[\"audio\"][\"sampling_rate\"])\n",
    "\n",
    "    # TIMIT Path\n",
    "    example[\"timit_path\"] = get_timit_path(\n",
    "        abs_path=wav_path, base_path=PATH_TO_TIMIT)\n",
    "\n",
    "    # Speaker Metadata\n",
    "    (dialect_region, dialect_region_name), (speaker_id, sex) = get_speaker_info(\n",
    "        example[\"timit_path\"])\n",
    "    example[\"dialect_region\"] = dialect_region\n",
    "    example[\"dialect_region_name\"] = dialect_region_name\n",
    "    example[\"speaker_id\"] = speaker_id\n",
    "    example[\"speaker_sex\"] = sex\n",
    "\n",
    "    # Sentence Metadata\n",
    "    sentence_id, sentence_type = get_sentence_info(wav_path)\n",
    "    example[\"id\"] = sentence_id\n",
    "    example[\"sentence_type\"] = sentence_type\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [01:25<00:00, 42.32 examples/s] \n",
      "Map: 100%|██████████| 1340/1340 [00:31<00:00, 42.04 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_with_metadata = train_dataset.map(add_metadata)\n",
    "testvalidation_dataset_with_metadata = testvalidation_dataset.map(add_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3) Upload Dataset to HuggingFace Hub\n",
    "- Note: we will upload the `testvalidation_dataset_with_metadata` as `test` in the TIMIT tradition\n",
    "- We will also create a train/validation/test split and have more features extracted from the data but do so in a different repository to remain consistent with the original TIMIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_asr_dataset_base = DatasetDict({\n",
    "    \"train\": train_dataset_with_metadata,\n",
    "    \"test\": testvalidation_dataset_with_metadata\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 3629\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 1340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Upload and Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [00:00<00:00, 9691.34 examples/s]s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 37/37 [00:00<00:00, 109.97ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:15<00:00, 15.23s/it]\n",
      "Map: 100%|██████████| 1340/1340 [00:00<00:00, 12737.90 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:00<00:00, 128.94ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kylelovesllms/timit_asr/commit/29c837c76686cb61f3efe199b0ea7d959b12f343', commit_message='Upload dataset', commit_description='', oid='29c837c76686cb61f3efe199b0ea7d959b12f343', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kylelovesllms/timit_asr', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kylelovesllms/timit_asr'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base.push_to_hub(\"kylelovesllms/timit_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timit_asr_dataset_base_from_hub \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "timit_asr_dataset_base_from_hub = load(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
