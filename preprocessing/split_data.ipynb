{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "- Splits the TIMIT dataset into a `TRAIN`, `VALIDATION`, `TEST` dataset\n",
    "- Note: the TIMIT dataset already comes with a `TEST` folder so we will simply take a % of the `TEST` dataset for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Import Audio\n",
    "- Create Training Dataset\n",
    "- Create Test Dataset\n",
    "- Since TIMIT does not differentiate between Test and Validation, we will manually split the Test into Test and Validation as a downstream task to respect the original naming conventions of the TIMIT dataset\n",
    "\n",
    "### Motivation\n",
    "The motivation for creating this dataset is because the existing `timit_asr` Hugging Face datasets do not use the complete TIMIT `TEST` and `TRAIN` data available. \n",
    "\n",
    "In addition, we also add  speaker gender and duration of speech.\n",
    "\n",
    "### Linguistic Distinction in categories\n",
    "`SA` = \"Speaker Accent\"/Dialect or Shibboleth sentences designed to highlight dialect region differences\n",
    "`SX` = Phonetically Compact sentences designed to highlight pairs of phones of interest (i.e. voiced vs unvoiced velar stops) in specific phonetic contexts (i.e. coda position = at the end of a word)\n",
    "`SI` = Phonetically Diverse sentences designed to highlight many different phonemes and sentence types per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio, DatasetDict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TIMIT = \"../data/input_data/TIMIT-Database/TIMIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(dir: str, file_type: str = \"wav\") -> dict[tuple[str, list[str]], tuple[str, list[str]]]:\n",
    "    \"\"\"\n",
    "    Walks through every directory in `dir` and returns all files which end in `file_type`\n",
    "    \"\"\"\n",
    "\n",
    "    audio_paths = {\"speech_tasks\": [], \"local_paths\": []}\n",
    "\n",
    "    # Walk through each directory\n",
    "    for dirpath, _dirnames, filenames in os.walk(dir):\n",
    "        # Check each file in the directory\n",
    "        for file_name in filenames:\n",
    "            # If the `file_type` matches\n",
    "            if file_name.endswith(file_type):\n",
    "                # Add that file\n",
    "                full_local_path = os.path.join(dirpath, file_name)\n",
    "                speech_task = file_name.removesuffix(f\".{file_type}\")\n",
    "\n",
    "                audio_paths[\"local_paths\"].append(full_local_path)\n",
    "                audio_paths[\"speech_tasks\"].append(speech_task)\n",
    "                \n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local paths ['../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX139.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SA2.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX229.wav']\n",
      "speech tasks ['SX139', 'SA2', 'SX229']\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check that we get the appropriate local paths and task names\n",
    "paths = get_audio_files(\"../data/input_data/TIMIT-Database/TIMIT/TEST\")\n",
    "print(\"local paths\", paths[\"local_paths\"][:3])\n",
    "print(\"speech tasks\", paths[\"speech_tasks\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(PATH_TO_TIMIT, \"TRAIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(train_path)[\"local_paths\"]]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../data/input_data/TIMIT-Database/TIMIT/TRAIN/DR4/MMDM0/SI681.wav',\n",
       " 'array': array([-2.13623047e-04,  6.10351562e-05,  3.05175781e-05, ...,\n",
       "        -3.05175781e-05, -9.15527344e-05, -6.10351562e-05]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity check to make sure we have valid audio files\n",
    "train_dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Add Metadata\n",
    "Although not all of the metadata is needed for this specific project, perhaps others in the open-source community will find this metadata helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
