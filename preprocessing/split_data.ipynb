{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "- Splits the TIMIT dataset into a `TRAIN`, `VALIDATION`, `TEST` dataset\n",
    "- Note: the TIMIT dataset already comes with a `TEST` folder so we will simply take a % of the `TEST` dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMIT_PATH = \"../data/input_data/TIMIT-Database/TIMIT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "timit = load_dataset(\"timit_asr\", data_dir=TIMIT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id'],\n",
      "        num_rows: 990\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id'],\n",
      "        num_rows: 340\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(timit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "Test Dialect Regions: {'DR7': 230, 'DR8': 110}\n",
      "Train Dialect Regions: {'DR3': 1, 'DR7': 769, 'DR8': 220}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id'],\n",
       "        num_rows: 990\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['file', 'audio', 'text', 'phonetic_detail', 'word_detail', 'dialect_region', 'sentence_type', 'speaker_id', 'id'],\n",
       "        num_rows: 340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(timit))\n",
    "\n",
    "test_dr_counts = {}\n",
    "for dr in timit[\"test\"][\"dialect_region\"]:\n",
    "    if dr in test_dr_counts:\n",
    "        test_dr_counts[dr] += 1\n",
    "    else:\n",
    "        test_dr_counts[dr] = 1\n",
    "\n",
    "print(f\"Test Dialect Regions: {test_dr_counts}\")\n",
    "\n",
    "train_dr_counts = {}\n",
    "for dr in timit[\"train\"][\"dialect_region\"]:\n",
    "    if dr in train_dr_counts:\n",
    "        train_dr_counts[dr] += 1\n",
    "    else:\n",
    "        train_dr_counts[dr] = 1\n",
    "\n",
    "print(f\"Train Dialect Regions: {train_dr_counts}\")\n",
    "\n",
    "timit \n",
    "\n",
    "# timit[\"train\"][\"file\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
