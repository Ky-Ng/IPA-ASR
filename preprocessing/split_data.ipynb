{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "- Splits the TIMIT dataset into a `TRAIN`, `VALIDATION`, `TEST` dataset\n",
    "- Note: the TIMIT dataset already comes with a `TEST` folder so we will simply take a % of the `TEST` dataset for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) Import Audio\n",
    "- Create Training Dataset\n",
    "- Create Test Dataset\n",
    "- Since TIMIT does not differentiate between Test and Validation, we will manually split the Test into Test and Validation as a downstream task to respect the original naming conventions of the TIMIT dataset\n",
    "\n",
    "### Motivation\n",
    "The motivation for creating this dataset is because the existing `timit_asr` Hugging Face datasets do not use the complete TIMIT `TEST` and `TRAIN` data available. \n",
    "\n",
    "In addition, we also add  speaker gender and duration of speech.\n",
    "\n",
    "### Linguistic Distinction in categories\n",
    "`SA` = \"Speaker Accent\"/Dialect or Shibboleth sentences designed to highlight dialect region differences\n",
    "`SX` = Phonetically Compact sentences designed to highlight pairs of phones of interest (i.e. voiced vs unvoiced velar stops) in specific phonetic contexts (i.e. coda position = at the end of a word)\n",
    "`SI` = Phonetically Diverse sentences designed to highlight many different phonemes and sentence types per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio, DatasetDict, load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timit_metadata_extractors import get_transcription_detail, get_speech_duration, get_replace_ending, get_timit_path, get_speaker_info, get_sentence_info, get_text, get_ipa_transcription\n",
    "from timit_dataset_splitter import stratify_timt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TIMIT = \"../data/input_data/TIMIT-Database/TIMIT\"\n",
    "UPLOAD_TIMIT_BASE_NAME= \"kylelovesllms/timit_asr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(dir: str, file_type: str = \"wav\") -> dict[tuple[str, list[str]], tuple[str, list[str]]]:\n",
    "    \"\"\"\n",
    "    Walks through every directory in `dir` and returns all files which end in `file_type`\n",
    "    \"\"\"\n",
    "\n",
    "    audio_paths = []\n",
    "\n",
    "    # Walk through each directory\n",
    "    for dirpath, _dirnames, filenames in os.walk(dir):\n",
    "        # Check each file in the directory\n",
    "        for file_name in filenames:\n",
    "            # If the `file_type` matches\n",
    "            if file_name.endswith(file_type):\n",
    "                # Add that file\n",
    "                full_local_path = os.path.join(dirpath, file_name)\n",
    "                audio_paths.append(full_local_path)\n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local paths ['../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX139.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SA2.wav', '../data/input_data/TIMIT-Database/TIMIT/TEST/DR4/MGMM0/SX229.wav']\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check that we get the appropriate local paths and task names\n",
    "paths = get_audio_files(\"../data/input_data/TIMIT-Database/TIMIT/TEST\")\n",
    "print(\"local paths\", paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(PATH_TO_TIMIT, \"TRAIN\")\n",
    "testvalidation_path = os.path.join(PATH_TO_TIMIT, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(train_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())\n",
    "\n",
    "testvalidation_dataset = Dataset.from_dict(\n",
    "     {\n",
    "        \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)]\n",
    "    }\n",
    ").cast_column(\"audio\", Audio())\n",
    "\n",
    "# TODO REMOVE AFTER DEBUGGING\n",
    "# train_dataset = Dataset.from_dict(\n",
    "#     {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(train_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())\n",
    "\n",
    "# testvalidation_dataset = Dataset.from_dict(\n",
    "#      {\n",
    "#         \"audio\": [audio_path for audio_path in get_audio_files(testvalidation_path)][:1]\n",
    "#     }\n",
    "# ).cast_column(\"audio\", Audio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio'],\n",
       "    num_rows: 3629\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '../data/input_data/TIMIT-Database/TIMIT/TRAIN/DR4/MMDM0/SI681.wav',\n",
       " 'array': array([-2.13623047e-04,  6.10351562e-05,  3.05175781e-05, ...,\n",
       "        -3.05175781e-05, -9.15527344e-05, -6.10351562e-05]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick sanity check to make sure we have valid audio files\n",
    "train_dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2) Add Metadata\n",
    "Although not all of the metadata is needed for this specific project, perhaps others in the open-source community will find this metadata helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata(example):\n",
    "    \"\"\"\n",
    "    Adds transcriptions and metadata to the TIMIT dataset\n",
    "\n",
    "    Note: after using `example[\"audio\"]`, the `example[\"audio\"][\"path\"]` is \n",
    "    automatically set to None for security reasons\n",
    "    (see Github Issue: https://github.com/huggingface/datasets/issues/5190)\n",
    "    \"\"\"\n",
    "    wav_path = example[\"audio\"][\"path\"]\n",
    "\n",
    "    # Add Transcriptions\n",
    "    phn_file = get_replace_ending(wav_path, new_extension=\".phn\")\n",
    "    wrd_file = get_replace_ending(wav_path, new_extension=\".wrd\")\n",
    "    text_file = get_replace_ending(wav_path, new_extension=\".txt\")\n",
    "\n",
    "    example[\"phonetic_detail\"] = get_transcription_detail(phn_file)\n",
    "    example[\"word_detail\"] = get_transcription_detail(wrd_file)\n",
    "    example[\"text\"] = get_text(text_file)\n",
    "\n",
    "    # Speech Duration\n",
    "    example[\"duration\"] = get_speech_duration(\n",
    "        example[\"audio\"][\"array\"], sr=example[\"audio\"][\"sampling_rate\"])\n",
    "\n",
    "    # TIMIT Path\n",
    "    example[\"timit_path\"] = get_timit_path(\n",
    "        abs_path=wav_path, base_path=PATH_TO_TIMIT)\n",
    "\n",
    "    # Speaker Metadata\n",
    "    (dialect_region, dialect_region_name), (speaker_id, sex) = get_speaker_info(\n",
    "        example[\"timit_path\"])\n",
    "    example[\"dialect_region\"] = dialect_region\n",
    "    example[\"dialect_region_name\"] = dialect_region_name\n",
    "    example[\"speaker_id\"] = speaker_id\n",
    "    example[\"speaker_sex\"] = sex\n",
    "\n",
    "    # Sentence Metadata\n",
    "    sentence_id, sentence_type = get_sentence_info(wav_path)\n",
    "    example[\"id\"] = sentence_id\n",
    "    example[\"sentence_type\"] = sentence_type\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  28%|██▊       | 999/3629 [00:41<01:49, 24.09 examples/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset_with_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m testvalidation_dataset_with_metadata \u001b[38;5;241m=\u001b[39m testvalidation_dataset\u001b[38;5;241m.\u001b[39mmap(add_metadata)\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3444\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3442\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_row(example\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[1;32m   3443\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3444\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3445\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_writer.py:537\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[0;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhkey_record \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_examples_on_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_writer.py:495\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m         batch_examples[col] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    492\u001b[0m             row[\u001b[38;5;241m0\u001b[39m][col]\u001b[38;5;241m.\u001b[39mto_pylist()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row[\u001b[38;5;241m0\u001b[39m][col], (pa\u001b[38;5;241m.\u001b[39mArray, pa\u001b[38;5;241m.\u001b[39mChunkedArray)) \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;241m0\u001b[39m][col]\n\u001b[1;32m    493\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples\n\u001b[1;32m    494\u001b[0m         ]\n\u001b[0;32m--> 495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_examples \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_writer.py:606\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    604\u001b[0m         typed_sequence \u001b[38;5;241m=\u001b[39m OptimizedTypedSequence(col_values, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mcol_type, try_type\u001b[38;5;241m=\u001b[39mcol_try_type, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[1;32m    605\u001b[0m         arrays\u001b[38;5;241m.\u001b[39mappend(pa\u001b[38;5;241m.\u001b[39marray(typed_sequence))\n\u001b[0;32m--> 606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m \u001b[43mtyped_sequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_inferred_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m    608\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_writer.py:168\u001b[0m, in \u001b[0;36mTypedSequence.get_inferred_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the inferred feature type.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03mThis is done by converting the sequence to an Arrow array, and getting the corresponding\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mfeature type.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    FeatureType: inferred feature type of the sequence.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type \u001b[38;5;241m=\u001b[39m generate_from_arrow_type(\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_type\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:250\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:114\u001b[0m, in \u001b[0;36mpyarrow.lib._handle_arrow_array_protocol\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/arrow_writer.py:243\u001b[0m, in \u001b[0;36mTypedSequence.__arrow_array__\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# otherwise we can finally use the user's type\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# We use cast_array_to_feature to support casting to custom types like Audio and Image\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# Also, when trying type \"string\", we don't want to convert integers or floats to \"string\".\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# We only do it if trying_type is False - since this is what the user asks for.\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mcast_array_to_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_primitive_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_decimal_to_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrying_type\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;167;01mTypeError\u001b[39;00m,\n\u001b[1;32m    249\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    250\u001b[0m     pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    251\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# handle type errors and overflows\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Ignore ArrowNotImplementedError caused by trying type, otherwise re-raise\u001b[39;00m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/table.py:1797\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/table.py:1995\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_primitive_to_str, allow_decimal_to_str)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mstorage\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast_storage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(array\u001b[38;5;241m.\u001b[39mtype):\n\u001b[1;32m   1998\u001b[0m     \u001b[38;5;66;03m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature\u001b[38;5;241m.\u001b[39mfeature, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/datasets/features/audio.py:234\u001b[0m, in \u001b[0;36mAudio.cast_storage\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m    232\u001b[0m     storage \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mStructArray\u001b[38;5;241m.\u001b[39mfrom_arrays([storage, path_array], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m], mask\u001b[38;5;241m=\u001b[39mstorage\u001b[38;5;241m.\u001b[39mis_null())\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype) \u001b[38;5;129;01mand\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mget_all_field_indices(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 234\u001b[0m     storage \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39marray([Audio()\u001b[38;5;241m.\u001b[39mencode_example(x) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_struct(storage\u001b[38;5;241m.\u001b[39mtype):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m storage\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mget_field_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/pyarrow/array.pxi:1656\u001b[0m, in \u001b[0;36mpyarrow.lib.Array.to_pylist\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/B_Organized/A_School/A_CSCI_467/Final_Proj/code/IPA-ASR/.venv/lib/python3.12/site-packages/pyarrow/scalar.pxi:794\u001b[0m, in \u001b[0;36mpyarrow.lib.StructScalar.as_py\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen _collections_abc>:819\u001b[0m, in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset_with_metadata = train_dataset.map(add_metadata)\n",
    "testvalidation_dataset_with_metadata = testvalidation_dataset.map(add_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3) Upload Dataset to HuggingFace Hub\n",
    "- Note: we will upload the `testvalidation_dataset_with_metadata` as `test` in the TIMIT tradition\n",
    "- We will also create a train/validation/test split and have more features extracted from the data but do so in a different repository to remain consistent with the original TIMIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_asr_dataset_base = DatasetDict({\n",
    "    \"train\": train_dataset_with_metadata,\n",
    "    \"test\": testvalidation_dataset_with_metadata\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 3629\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
       "        num_rows: 1340\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Upload and Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [00:00<00:00, 11345.77 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 37/37 [00:00<00:00, 124.08ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Map: 100%|██████████| 1340/1340 [00:00<00:00, 14438.26 examples/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:00<00:00, 129.18ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kylelovesllms/timit_asr/commit/29c837c76686cb61f3efe199b0ea7d959b12f343', commit_message='Upload dataset', commit_description='', oid='29c837c76686cb61f3efe199b0ea7d959b12f343', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/kylelovesllms/timit_asr', endpoint='https://huggingface.co', repo_type='dataset', repo_id='kylelovesllms/timit_asr'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timit_asr_dataset_base.push_to_hub(UPLOAD_TIMIT_BASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_asr_dataset_base_from_hub = load_dataset(UPLOAD_TIMIT_BASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
      "        num_rows: 3629\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'phonetic_detail', 'word_detail', 'text', 'duration', 'timit_path', 'dialect_region', 'dialect_region_name', 'speaker_id', 'speaker_sex', 'id', 'sentence_type'],\n",
      "        num_rows: 1340\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Verify that the repository is pulled down correctly\n",
    "print(timit_asr_dataset_base_from_hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4) Adding Phonetic Transcriptions\n",
    "- Although the TIMIT IPA has a `phonetic_detail` which is documented in `TIMIT/DOC/PHONCODE.DOC`, some downstream use cases may require the use of transcription records in the International Phonetic Alphabet (IPA) format\n",
    "- This format is universal accross almost every tradition in phonetics \n",
    "- Note: the transcription scheme used in the repository below is not peer reviewed and is specific to a broad transcription for evaluating a fine tuned Wav2Vec2 model against Wav2Vec2-XLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ipa_transcription(example):\n",
    "    \"\"\"\n",
    "    Returns an interpretation of the IPA transcription in the `ipa_transcription` property\n",
    "    \"\"\"\n",
    "    example_with_metadata = add_metadata(example)\n",
    "    example_with_metadata[\"ipa_transcription\"] = get_ipa_transcription(example_with_metadata[\"phonetic_detail\"])\n",
    "    return example_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3629/3629 [01:27<00:00, 41.40 examples/s] \n",
      "Map: 100%|██████████| 1340/1340 [00:32<00:00, 41.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_with_ipa = train_dataset.map(add_ipa_transcription)\n",
    "testvalidation_dataset_with_ipa = testvalidation_dataset.map(add_ipa_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would such an act of refusal be useful?\n",
      "['h#', 'w', 'ix', 'dcl', 's', 'ah', 'tcl', 'ch', 'ix', 'n', 'ae', 'kcl', 't', 'ix', 'v', 'r', 'ix', 'f', 'y', 'ux', 'zh', 'el', 'bcl', 'b', 'iy', 'y', 'ux', 's', 'f', 'el', 'h#']\n",
      "['w', 'ɪ', 'd', 's', 'ʌ', 't', 'tʃ', 'ɪ', 'n', 'æ', 'k', 't', 'ɪ', 'v', 'r', 'ɪ', 'f', 'j', 'u', 'ʒ', 'l', 'b', 'i', 'j', 'u', 's', 'f', 'l']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the transcriptions\n",
    "print(train_dataset_with_ipa[0][\"text\"])\n",
    "print([seg[\"utterance\"] for seg in train_dataset_with_ipa[0][\"phonetic_detail\"]])\n",
    "print(train_dataset_with_ipa[0][\"ipa_transcription\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bungalow was pleasantly situated near the shore.\n",
      "['h#', 'dh', 'ax', 'bcl', 'b', 'ah', 'ng', 'g', 'ax', 'l', 'ow', 'w', 'ax', 'z', 'pcl', 'p', 'l', 'eh', 'z', 'ax', 'n', 'q', 'l', 'iy', 's', 'ih', 'tcl', 'ch', 'uw', 'w', 'ey', 'dx', 'ix', 'dcl', 'n', 'ih', 'axr', 'dh', 'ix', 'sh', 'ao', 'r', 'h#']\n",
      "['ð', 'ə', 'b', 'ʌ', 'ŋ', 'g', 'ə', 'l', 'oʊ', 'w', 'ə', 'z', 'p', 'l', 'ɛ', 'z', 'ə', 'n', 'ʔ', 'l', 'i', 's', 'ɪ', 't', 'tʃ', 'u', 'w', 'eɪ', 'ɾ', 'ɪ', 'd', 'n', 'ɪ', 'ɚ', 'ð', 'ɪ', 'ʃ', 'ɔ', 'r']\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the transcriptions\n",
    "print(testvalidation_dataset_with_ipa[0][\"text\"])\n",
    "print([seg[\"utterance\"] for seg in testvalidation_dataset_with_ipa[0][\"phonetic_detail\"]])\n",
    "print(testvalidation_dataset_with_ipa[0][\"ipa_transcription\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5) Add Validation Split\n",
    "- The original TIMIT dataset has only `TRAIN` and `TEST`\n",
    "- Thus, we will create an 80-10-10 `TRAIN`/ `VALIDATION` / `TEST`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification\n",
    "- The TIMIT dataset is carefully split into a `TRAIN` and `TEST` dataset.\n",
    "- When making the Validation dataset from splitting the `TEST` dataset in half, we want to `stratify` or keep the proportion of speakers the same to ensure accurate hyperparameter tuning and final test evaluation\n",
    "- The parameters that the TIMIT dataset stratifies on for `TRAIN` and `TEST` is `sex` and `dialect_region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify_timt_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
